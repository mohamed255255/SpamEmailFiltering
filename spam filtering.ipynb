{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJOJ8OgNexUE",
        "outputId": "28dd0ba0-bb79-4574-f02f-2818995e9ecd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\Ahmed\n",
            "[nltk_data]     M.Sallam\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk import pos_tag\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bd9DABUThvxI"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From ilugadminlinuxie Mon Jul 29 112802 2002 R...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From gort44excitecom Mon Jun 24 175421 2002 Re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From forkadminxentcom Mon Jul 29 113957 2002 R...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From dcm123btamailnetcn Mon Jun 24 174923 2002...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From ilugadminlinuxie Mon Aug 19 110247 2002 R...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5791</th>\n",
              "      <td>From ilugadminlinuxie Mon Jul 22 181245 2002 R...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5792</th>\n",
              "      <td>From forkadminxentcom Mon Oct 7 203702 2002 Re...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5793</th>\n",
              "      <td>Received from hqpronsnet localhost 127001 by h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5794</th>\n",
              "      <td>From razorusersadminlistssourceforgenet Thu Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5795</th>\n",
              "      <td>From rssfeedsjmasonorg Mon Sep 30 134410 2002 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5796 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  target\n",
              "0     From ilugadminlinuxie Mon Jul 29 112802 2002 R...       0\n",
              "1     From gort44excitecom Mon Jun 24 175421 2002 Re...       1\n",
              "2     From forkadminxentcom Mon Jul 29 113957 2002 R...       1\n",
              "3     From dcm123btamailnetcn Mon Jun 24 174923 2002...       1\n",
              "4     From ilugadminlinuxie Mon Aug 19 110247 2002 R...       0\n",
              "...                                                 ...     ...\n",
              "5791  From ilugadminlinuxie Mon Jul 22 181245 2002 R...       0\n",
              "5792  From forkadminxentcom Mon Oct 7 203702 2002 Re...       0\n",
              "5793  Received from hqpronsnet localhost 127001 by h...       1\n",
              "5794  From razorusersadminlistssourceforgenet Thu Se...       0\n",
              "5795  From rssfeedsjmasonorg Mon Sep 30 134410 2002 ...       0\n",
              "\n",
              "[5796 rows x 2 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df  = pd.read_csv(\"Spam_Email_Data.csv\")\n",
        "def data_cleaning(text):\n",
        "    clean_text = re.sub('<.*?>', '', text) # remove HTML tags\n",
        "    clean_text = re.sub(r'[^\\w\\s]', '', clean_text)  # remove punctuation\n",
        "    clean_text = re.sub(r'\\b\\d{4}-\\d{2}-\\d{2}\\b', '', clean_text)# remove dates\n",
        "    clean_text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', clean_text)# remove email addresses\n",
        "    return clean_text\n",
        "\n",
        "df['text'] = df['text'].apply(data_cleaning)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ry4WfTGxhw9e"
      },
      "outputs": [],
      "source": [
        "def text_processing(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Stop word removal\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "\n",
        "   # Part-of-speech tagging\n",
        "    pos_tokens = pos_tag(filtered_tokens)\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in pos_tokens]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    processed_text = ' '.join([token for token, pos in lemmatized_tokens])\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0-OvtwgvDqBe"
      },
      "outputs": [],
      "source": [
        "final = []\n",
        "\n",
        "\n",
        "def model_accuracy(model_name, y_test, y_pred):\n",
        "    accuracy_test = accuracy_score(y_test, y_pred)\n",
        "    precision_test = precision_score(y_test, y_pred)\n",
        "    recall_test = recall_score(y_test, y_pred)\n",
        "    f1_test = f1_score(y_test, y_pred)\n",
        "\n",
        "    final.append({\n",
        "        'model': model_name,\n",
        "        'accuracy_test': accuracy_test,\n",
        "        'precision_test': precision_test,\n",
        "        # 'recall_test': recall_test,\n",
        "        # 'f1_test': f1_test\n",
        "    })\n",
        "\n",
        "    return accuracy_test, precision_test #, recall_test, f1_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "31rWjiojDXo8"
      },
      "outputs": [],
      "source": [
        "x_train , x_test , y_train , y_test = train_test_split(df['text'] , df['target'] , test_size=0.4 , random_state=50)\n",
        "\n",
        "sentences = [row.split() for row in x_train]\n",
        "word2vec_model = Word2Vec(sentences , vector_size = 100)\n",
        "\n",
        "\n",
        "def get_word2vec_embedding(text):\n",
        "    words = text.split()\n",
        "    embeding =  np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv], axis=0)\n",
        "    return embeding\n",
        "\n",
        "\n",
        "x_train_w2v = np.array([get_word2vec_embedding(text) for text in x_train])\n",
        "x_test_w2v  = np.array([get_word2vec_embedding(text) for text in x_test])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nrMZG6gPDdZV"
      },
      "outputs": [],
      "source": [
        "# Create a logistic regression model\n",
        "logistic_model = LogisticRegression(C=0.5, random_state=50)\n",
        "\n",
        "\n",
        "logistic_model.fit(x_train_w2v , y_train)\n",
        "\n",
        "\n",
        "y_pred_log = logistic_model.predict(x_test_w2v)\n",
        "\n",
        "accuracy_w2v, precision_w2v = model_accuracy(\"Logistic Regression (w2v)\", y_test, y_pred_log)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iyOULhgQDm9V"
      },
      "outputs": [],
      "source": [
        "# TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "x_train_tfidf = tfidf.fit_transform(x_train)\n",
        "x_test_tfidf = tfidf.transform(x_test)\n",
        "\n",
        "# Bag of Words (BoW) Vectorizer\n",
        "bow = CountVectorizer()\n",
        "x_train_bow = bow.fit_transform(x_train)\n",
        "x_test_bow = bow.transform(x_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HfXZCGx2Duce"
      },
      "outputs": [],
      "source": [
        "# Train logistic regression model using TF-IDF features\n",
        "logistic_model_tfidf = LogisticRegression(C=0.5, random_state=50)\n",
        "logistic_model_tfidf.fit(x_train_tfidf, y_train)\n",
        "y_pred_log_tfidf = logistic_model_tfidf.predict(x_test_tfidf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvoDx9zWDyGp",
        "outputId": "363cd5ff-da04-478e-dc54-fdda2e39dbb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 0, 1], dtype=int64)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_log_tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-GuK9SND1JT",
        "outputId": "70288c3b-d6aa-4185-8a77-42fa584214bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Train logistic regression model using BoW features\n",
        "logistic_model_bow = LogisticRegression(C=0.5, random_state=50)\n",
        "logistic_model_bow.fit(x_train_bow, y_train)\n",
        "y_pred_log_bow = logistic_model_bow.predict(x_test_bow)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFECKYAxD3jz",
        "outputId": "3100d722-9887-493b-ae1d-bcc02ecf04d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 0, 1], dtype=int64)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_log_bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLTnudNZD9oM",
        "outputId": "a8f6a378-fe31-4983-8d22-ded861565da4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9948253557567918, 0.994579945799458)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate models\n",
        "model_accuracy(\"Logistic Regression (TF-IDF)\", y_test, y_pred_log_tfidf)\n",
        "model_accuracy(\"Logistic Regression (BoW)\", y_test, y_pred_log_bow)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvXvtD3nEC51",
        "outputId": "71a29fbc-e853-488d-cd8d-22dec2920ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          model  accuracy_test  precision_test\n",
            "0     Logistic Regression (w2v)       0.982751        0.984807\n",
            "1  Logistic Regression (TF-IDF)       0.969815        0.997041\n",
            "2     Logistic Regression (BoW)       0.994825        0.994580\n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "results_df = pd.DataFrame(final)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hui6P7GaEHED"
      },
      "outputs": [],
      "source": [
        "# Doc2Vec\n",
        "\n",
        "\n",
        "# Tag documents\n",
        "td_train = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(x_train)]\n",
        "td_test = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(x_test)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "11FjlwJBEMGw"
      },
      "outputs": [],
      "source": [
        "# Train Doc2Vec model\n",
        "doc2vec_model = Doc2Vec(td_train, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "x_train_doc2vec = np.array([doc2vec_model.infer_vector(doc.words) for doc in td_train])\n",
        "x_test_doc2vec = np.array([doc2vec_model.infer_vector(doc.words) for doc in td_test])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sKAkRcxlEp5C"
      },
      "outputs": [],
      "source": [
        "# Train logistic regression model using Doc2Vec features with increased max_iter\n",
        "dec2vec_logistic_model = LogisticRegression(C=0.5, random_state=50, max_iter=1000)  # Increase max_iter\n",
        "dec2vec_logistic_model.fit(x_train_doc2vec, y_train)\n",
        "y_pred_log_doc2vec = dec2vec_logistic_model.predict(x_test_doc2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KIztjyXEFePr"
      },
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "accuracy_doc2vec, precision_doc2vec = model_accuracy(\"Logistic Regression (Doc2Vec)\", y_test, y_pred_log_doc2vec)\n",
        "\n",
        "# # Display results\n",
        "# final.append({\n",
        "#     'model': \"Logistic Regression (Doc2Vec)\",\n",
        "#     'accuracy_test': accuracy_doc2vec,\n",
        "#     'precision_test': precision_doc2vec,\n",
        "#     'recall_test': recall_doc2vec,\n",
        "#     'f1_test': f1_doc2vec\n",
        "# })\n",
        "# results_df = pd.DataFrame(final)\n",
        "# print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDP4t0vZFq8z",
        "outputId": "b2bed5c5-b150-483b-eb91-805f976a34c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9534282018111255, 0.9260752688172043)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Decision Tree with Word2Vec\n",
        "decision_tree_w2v = DecisionTreeClassifier(random_state=50)\n",
        "decision_tree_w2v.fit(x_train_w2v, y_train)\n",
        "y_pred_dt_w2v = decision_tree_w2v.predict(x_test_w2v)\n",
        "model_accuracy(\"Decision Tree (Word2Vec)\", y_test, y_pred_dt_w2v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4tzOpxIQ-el",
        "outputId": "f33c1c4d-08ca-4207-df60-e205eb856470"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.8801207416990082, 0.8093333333333333)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Decision Tree with Doc2Vec\n",
        "decision_tree_doc2vec = DecisionTreeClassifier(random_state=50)\n",
        "decision_tree_doc2vec.fit(x_train_doc2vec, y_train)\n",
        "y_pred_dt_doc2vec = decision_tree_doc2vec.predict(x_test_doc2vec)\n",
        "model_accuracy(\"Decision Tree (Doc2Vec)\", y_test, y_pred_dt_doc2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ_xkY4fRAp0",
        "outputId": "e9b0bc2e-a26b-4e37-eb04-fbeaff69ffae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9780077619663649, 0.9564068692206077)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Decision Tree with TF-IDF\n",
        "decision_tree_tfidf = DecisionTreeClassifier(random_state=50)\n",
        "decision_tree_tfidf.fit(x_train_tfidf, y_train)\n",
        "y_pred_dt_tfidf = decision_tree_tfidf.predict(x_test_tfidf)\n",
        "model_accuracy(\"Decision Tree (TF-IDF)\", y_test, y_pred_dt_tfidf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y71--myTRCWM",
        "outputId": "61ff8b39-7f88-47d3-dabe-be2af1825078"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9793014230271668, 0.9602122015915119)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Decision Tree with Bag of Words\n",
        "decision_tree_bow = DecisionTreeClassifier(random_state=50)\n",
        "decision_tree_bow.fit(x_train_bow, y_train)\n",
        "y_pred_dt_bow = decision_tree_bow.predict(x_test_bow)\n",
        "model_accuracy(\"Decision Tree (BoW)\", y_test, y_pred_dt_bow)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz3lfKZpRD-N",
        "outputId": "bd5578e3-0db4-4883-a137-d63dbaef7dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                           model  accuracy_test  precision_test\n",
            "0      Logistic Regression (w2v)       0.982751        0.984807\n",
            "1   Logistic Regression (TF-IDF)       0.969815        0.997041\n",
            "2      Logistic Regression (BoW)       0.994825        0.994580\n",
            "3  Logistic Regression (Doc2Vec)       0.967658        0.973050\n",
            "4       Decision Tree (Word2Vec)       0.953428        0.926075\n",
            "5        Decision Tree (Doc2Vec)       0.880121        0.809333\n",
            "6         Decision Tree (TF-IDF)       0.978008        0.956407\n",
            "7            Decision Tree (BoW)       0.979301        0.960212\n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "results_df = pd.DataFrame(final)\n",
        "print(results_df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
